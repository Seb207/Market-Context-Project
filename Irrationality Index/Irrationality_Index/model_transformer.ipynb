{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOzYSlBXeZV8ZDOmhVa4vIa",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Seb207/Market-Context-Project/blob/main/Irrationality%20Index/DL_Index_Outline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning for Index Outline\n",
    "\n",
    "Outline for deep learning model to analze market factors and output irrationality index.\n",
    "\n",
    "Model: Transformer\n",
    "\n",
    "Data_Format: history data in second\n",
    "\n",
    "- Positional Embedding Class\n",
    "- Transformer Encoder Block Class\n",
    "- Prediction Head Class\n",
    "- Irrationality Index Class\n",
    "- Model Manager Class"
   ],
   "metadata": {
    "id": "MTQce3MpdVNI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hypothesis\n",
    "\n",
    "**Factors**\n",
    "- Volatility: VIX (moving avg. - 20 days)\n",
    "- Volume: Trading Volume (periodic average - 20 days)\n",
    "- Fixed Income (macro): US bond rate momentum\n",
    "- Periodicity: past rate of return (20, 60, 120 days)\n",
    "- Small vs. Big performace: (QQQ -> factor: IWM, IWM -> factor: QQQ) rate of return\n",
    "-\n",
    "\n",
    "**Tested Data**\n",
    "- SPY (S&P 500)\n",
    "- QQQ (Nasdaq)\n",
    "- DIA (Dow Jones)\n",
    "- IWM (Russell 2000)\n",
    "- Individual stocks\n",
    "\n",
    "1."
   ],
   "metadata": {
    "id": "U-azsMTEm0MD"
   }
  },
  {
   "metadata": {
    "id": "hFh0HZGCdWdV"
   },
   "cell_type": "markdown",
   "source": "# Import Libraries"
  },
  {
   "metadata": {
    "id": "pS0K6BZ2c8F1",
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.211531Z",
     "start_time": "2025-11-26T03:20:01.199864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import scipy.stats as stats\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout,\n",
    "    LayerNormalization, MultiHeadAttention,\n",
    "    Lambda\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, mean_absolute_percentage_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "id": "3uZMrXIAsg4z"
   },
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Problem 1:\n",
    "- As factors have each different absolute values, output could be affected by its absolute value if directly used as input.\n",
    "\n",
    "Solution:\n",
    "- Used data normalization (z-score)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.233453Z",
     "start_time": "2025-11-26T03:20:01.216895Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('../Data/Index/1424_daily_cleaned.csv', index_col=0, parse_dates=True)",
   "outputs": [],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.245374Z",
     "start_time": "2025-11-26T03:20:01.237983Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2501 entries, 2015-01-02 to 2024-12-31\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   QQQ_Price_Close  2501 non-null   float64\n",
      " 1   QQQ_Volume       2501 non-null   float64\n",
      " 2   SPY_Price_Close  2501 non-null   float64\n",
      " 3   SPY_Volume       2501 non-null   float64\n",
      " 4   US10_Mid_Price   2501 non-null   float64\n",
      " 5   US10_Mid_Yld     2501 non-null   float64\n",
      " 6   US30_Mid_Price   2501 non-null   float64\n",
      " 7   US30_Mid_Yld     2501 non-null   float64\n",
      " 8   GLD_Price_Close  2501 non-null   float64\n",
      " 9   GLD_Volume       2501 non-null   float64\n",
      " 10  IWM_Price_Close  2501 non-null   float64\n",
      " 11  IWM_Volume       2501 non-null   float64\n",
      " 12  VIX              2501 non-null   float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 273.5 KB\n"
     ]
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.250384Z",
     "start_time": "2025-11-26T03:20:01.249112Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.258737Z",
     "start_time": "2025-11-26T03:20:01.257069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_features = ['QQQ_Volume', 'US10_Mid_Yld', 'GLD_Price_Close', 'IWM_Price_Close', 'VIX']\n",
    "target = 'QQQ_Price_Close' # Assume the target to be the price data in this case."
   ],
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.265106Z",
     "start_time": "2025-11-26T03:20:01.262118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correlation_df = df.corr()\n",
    "\n",
    "print(correlation_df[target].sort_values(ascending=False))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQQ_Price_Close    1.000000\n",
      "SPY_Price_Close    0.993463\n",
      "GLD_Price_Close    0.947892\n",
      "IWM_Price_Close    0.897019\n",
      "US10_Mid_Yld       0.452836\n",
      "US30_Mid_Yld       0.397922\n",
      "QQQ_Volume         0.229553\n",
      "VIX                0.123486\n",
      "IWM_Volume         0.075931\n",
      "GLD_Volume        -0.077556\n",
      "US30_Mid_Price    -0.109676\n",
      "US10_Mid_Price    -0.131958\n",
      "SPY_Volume        -0.307432\n",
      "Name: QQQ_Price_Close, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.346472Z",
     "start_time": "2025-11-26T03:20:01.272965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correlation_matrix = df[input_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix,\n",
    "            annot=True,\n",
    "            cmap='coolwarm',\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            center=0)\n",
    "plt.title('Heatmap of Feature Correlations')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.351662Z",
     "start_time": "2025-11-26T03:20:01.349710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_features = [target] + input_features\n",
    "data_array = df[selected_features].values\n",
    "num_features = len(selected_features)"
   ],
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.359330Z",
     "start_time": "2025-11-26T03:20:01.357531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(dataset, look_back=1, target_col_index=0):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        seq_input = dataset[i: (i + look_back), :]\n",
    "        X.append(seq_input)\n",
    "        seq_target = dataset[i + look_back, target_col_index]\n",
    "        Y.append(seq_target)\n",
    "    return np.array(X), np.array(Y)"
   ],
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.365318Z",
     "start_time": "2025-11-26T03:20:01.361348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "look_back = 20 # days 20 days --> 1 month\n",
    "X, Y = create_dataset(data_array,\n",
    "                      look_back,\n",
    "                      target_col_index=0\n",
    "                      )\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=False\n",
    "                                                    )\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp,\n",
    "                                                  test_size=0.5,\n",
    "                                                  random_state=42,\n",
    "                                                  shuffle=False\n",
    "                                                  )"
   ],
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.372077Z",
     "start_time": "2025-11-26T03:20:01.367484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_samples, n_timesteps, n_features = X_train.shape\n",
    "X_train_2d = X_train.reshape(n_samples * n_timesteps, n_features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_2d = scaler.fit_transform(X_train_2d)\n",
    "\n",
    "X_train_scaled = X_train_scaled_2d.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "X_val_2d = X_val.reshape(-1, n_features)\n",
    "X_val_scaled = scaler.transform(X_val_2d).reshape(X_val.shape)\n",
    "\n",
    "X_test_2d = X_test.reshape(-1, n_features)\n",
    "X_test_scaled = scaler.transform(X_test_2d).reshape(X_test.shape)"
   ],
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.376428Z",
     "start_time": "2025-11-26T03:20:01.374368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler_y = StandardScaler()\n",
    "Y_train_scaled = scaler_y.fit_transform(Y_train.reshape(-1, 1)).flatten()\n",
    "Y_val_scaled = scaler_y.transform(Y_val.reshape(-1, 1)).flatten()\n",
    "Y_test_scaled = scaler_y.transform(Y_test.reshape(-1, 1)).flatten()"
   ],
   "outputs": [],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.381048Z",
     "start_time": "2025-11-26T03:20:01.379319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"X_train shape: {X_train_scaled.shape}\")\n",
    "print(f\"Y_train shape: {Y_train_scaled.shape}\")\n",
    "print(f\"X_val shape: {X_val_scaled.shape}\")\n",
    "print(f\"Y_val shape: {Y_val_scaled.shape}\")\n",
    "print(f\"X_test shape: {X_test_scaled.shape}\")\n",
    "print(f\"Y_test shape: {Y_test_scaled.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1984, 20, 6)\n",
      "Y_train shape: (1984,)\n",
      "X_val shape: (248, 20, 6)\n",
      "Y_val shape: (248,)\n",
      "X_test shape: (248, 20, 6)\n",
      "Y_test shape: (248,)\n"
     ]
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "id": "AaPi-z4H1Tqm"
   },
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters\n",
    "\n",
    "**Model Architecture**\n",
    "- input_dim: number of factors\n",
    "- seq_len: length of data processed in the model at once\n",
    "- d_model: dimension of the model\n",
    "- num_heads: number of heads for multi-head attention (should be divisor of d_model)\n",
    "- d_ff: inner dimension of feed forward (4x of d_model in usual)\n",
    "- num_layers: number of transformer encoder block (depth of model)\n",
    "- output_dim: output dimension\n",
    "\n",
    "**Training and Normalization**\n",
    "- dropout_rate\n",
    "- learning_rate\n",
    "- batch_size"
   ]
  },
  {
   "metadata": {
    "id": "bNvZPjRZkSP-"
   },
   "cell_type": "markdown",
   "source": [
    "# Transformer Encoder Block Class\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "id": "4sIoy3nmgVLX",
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.391606Z",
     "start_time": "2025-11-26T03:20:01.387991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\"`embed_dim` must be divisible by `num_heads`.\")\n",
    "        key_dim = embed_dim // num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "        self.ffn = Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        attn_output = self.att(inputs, inputs, attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'dropout_rate': self.dropout_rate\n",
    "        })\n",
    "        return config"
   ],
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "id": "gfAA-KoyuqZO"
   },
   "cell_type": "markdown",
   "source": "# Positional Embedding Class"
  },
  {
   "metadata": {
    "id": "1vQHozFfutbs",
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.399122Z",
     "start_time": "2025-11-26T03:20:01.396270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, embed_dim, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.max_len = max_len\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pos = np.arange(self.max_len)[:, np.newaxis]  # (max_len, 1)\n",
    "        i = np.arange(self.embed_dim)[np.newaxis, :]  # (1, embed_dim)\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(self.embed_dim))\n",
    "        angle_rads = pos * angle_rates  # (max_len, embed_dim)\n",
    "\n",
    "        # apply sin to even indices; cos to odd indices\n",
    "        pos_encoding = np.zeros_like(angle_rads, dtype=np.float32)\n",
    "        pos_encoding[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        pos_encoding[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # shape -> (1, max_len, embed_dim) to allow broadcasting with batch\n",
    "        pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "        self.pos_encoding = tf.constant(pos_encoding, dtype=tf.float32)\n",
    "        super(PositionalEncoding, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # x shape: (batch, seq_len, embed_dim)\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        return x + self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'max_len': self.max_len, 'embed_dim': self.embed_dim})\n",
    "        return config"
   ],
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "id": "CscGGS6Cu6JR"
   },
   "cell_type": "markdown",
   "source": "# Transformer Model Building Function"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.414956Z",
     "start_time": "2025-11-26T03:20:01.413131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_transformer_model_wrapper(\n",
    "    look_back_size, num_features,\n",
    "    embed_dim=64, num_heads=4, ff_dim=128,\n",
    "    num_transformer_blocks=2, dropout_rate=0.2, learning_rate=0.001):\n",
    "\n",
    "    return build_transformer_model(\n",
    "        look_back_size, num_features, embed_dim, num_heads,\n",
    "        ff_dim, num_transformer_blocks, dropout_rate, learning_rate\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.420258Z",
     "start_time": "2025-11-26T03:20:01.417373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_transformer_model(look_back_size, num_features,\n",
    "                           embed_dim=64, num_heads=4,\n",
    "                           ff_dim=128, num_transformer_blocks=2,\n",
    "                           dropout_rate=0.2, learning_rate=0.001):\n",
    "    inputs = Input(shape=(look_back_size, num_features))\n",
    "    x = Dense(embed_dim)(inputs)\n",
    "    x = PositionalEncoding(look_back_size, embed_dim)(x)\n",
    "\n",
    "    # causal mask (no look-ahead): shape (1, seq_len, seq_len) -> broadcasts over batch\n",
    "    causal_mask = tf.cast(\n",
    "        tf.linalg.band_part(tf.ones((look_back_size, look_back_size)), -1, 0),\n",
    "        dtype=tf.bool\n",
    "    )\n",
    "    causal_mask = tf.expand_dims(causal_mask, axis=0)\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = TransformerBlock(embed_dim, num_heads, ff_dim, dropout_rate)(x, mask=causal_mask)\n",
    "\n",
    "    x = Lambda(lambda t: tf.reduce_mean(t, axis=1))(x)\n",
    "\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.Huber(delta=1.0),\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse'), 'mae'])\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "id": "q1YiFxWavskV"
   },
   "cell_type": "markdown",
   "source": "# Training & Tuning Data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:20:01.426974Z",
     "start_time": "2025-11-26T03:20:01.424061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_distributions = {\n",
    "    'model__embed_dim': [64, 128, 256, 384, 512],\n",
    "    'model__num_heads': [1, 2, 4, 8],\n",
    "    'model__ff_dim': [128, 256, 512, 1024, 2048],\n",
    "    'model__num_transformer_blocks': [1, 2, 3, 4],\n",
    "    'model__dropout_rate': stats.uniform(0.05, 0.45),\n",
    "    'model__learning_rate': stats.loguniform(1e-5, 1e-2),\n",
    "    'batch_size': [16, 32, 64, 128, 256],\n",
    "    'epochs': [20, 50, 100]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T03:24:01.009029Z",
     "start_time": "2025-11-26T03:20:01.431093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Starting hyperparameter tuning using RandomizedSearchCV...\")\n",
    "\n",
    "# Create a KerasRegressor wrapper\n",
    "# The build_fn is passed the fixed look_back and num_features.\n",
    "# Other parameters like embed_dim, num_heads etc. will be passed by RandomizedSearchCV.\n",
    "keras_model = KerasRegressor(\n",
    "    model=build_transformer_model,\n",
    "    look_back_size=look_back,\n",
    "    num_features=num_features,\n",
    "    verbose=0,\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"huber\"\n",
    ")\n",
    "\n",
    "callbacks_list = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "]\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=keras_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(\n",
    "    X_train_scaled, Y_train_scaled,\n",
    "    validation_data=(X_val_scaled, Y_val_scaled),\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Hyperparameter tuning completed!\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning using RandomizedSearchCV...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_60' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_61' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_62' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_63' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_64' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_65' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_66' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_67' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_68' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_69' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_70' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_71' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_72' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_72' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_73' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_73' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_74' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_74' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_75' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_75' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_76' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_76' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_77' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_77' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_78' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_79' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_80' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_81' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_82' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_83' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_84' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_85' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_86' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_87' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_88' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_89' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_90' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_90' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/ahnsebin/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'lambda_91' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[191]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     15\u001B[39m callbacks_list = [\n\u001B[32m     16\u001B[39m     EarlyStopping(monitor=\u001B[33m'\u001B[39m\u001B[33mval_loss\u001B[39m\u001B[33m'\u001B[39m, patience=\u001B[32m5\u001B[39m, restore_best_weights=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m     17\u001B[39m     ReduceLROnPlateau(monitor=\u001B[33m'\u001B[39m\u001B[33mval_loss\u001B[39m\u001B[33m'\u001B[39m, factor=\u001B[32m0.5\u001B[39m, patience=\u001B[32m3\u001B[39m, min_lr=\u001B[32m1e-5\u001B[39m)\n\u001B[32m     18\u001B[39m ]\n\u001B[32m     20\u001B[39m random_search = RandomizedSearchCV(\n\u001B[32m     21\u001B[39m     estimator=keras_model,\n\u001B[32m     22\u001B[39m     param_distributions=param_distributions,\n\u001B[32m   (...)\u001B[39m\u001B[32m     28\u001B[39m     random_state=\u001B[32m42\u001B[39m\n\u001B[32m     29\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m \u001B[43mrandom_search\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train_scaled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_val_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val_scaled\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks_list\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m + \u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m * \u001B[32m60\u001B[39m)\n\u001B[32m     38\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mHyperparameter tuning completed!\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/sklearn/base.py:1365\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1358\u001B[39m     estimator._validate_params()\n\u001B[32m   1360\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1361\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1362\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1363\u001B[39m     )\n\u001B[32m   1364\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1365\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051\u001B[39m, in \u001B[36mBaseSearchCV.fit\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m   1045\u001B[39m     results = \u001B[38;5;28mself\u001B[39m._format_results(\n\u001B[32m   1046\u001B[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[32m   1047\u001B[39m     )\n\u001B[32m   1049\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[32m-> \u001B[39m\u001B[32m1051\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1053\u001B[39m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[32m   1054\u001B[39m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[32m   1055\u001B[39m first_test_score = all_out[\u001B[32m0\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mtest_scores\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1992\u001B[39m, in \u001B[36mRandomizedSearchCV._run_search\u001B[39m\u001B[34m(self, evaluate_candidates)\u001B[39m\n\u001B[32m   1990\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[32m   1991\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1992\u001B[39m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1993\u001B[39m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1994\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrandom_state\u001B[49m\n\u001B[32m   1995\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1996\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:997\u001B[39m, in \u001B[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[39m\u001B[34m(candidate_params, cv, more_results)\u001B[39m\n\u001B[32m    989\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose > \u001B[32m0\u001B[39m:\n\u001B[32m    990\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[32m    991\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[33m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[33m candidates,\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    992\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m fits\u001B[39m\u001B[33m\"\u001B[39m.format(\n\u001B[32m    993\u001B[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001B[32m    994\u001B[39m         )\n\u001B[32m    995\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m997\u001B[39m out = \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    998\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    999\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1000\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1001\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1002\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1003\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1004\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1005\u001B[39m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1006\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1007\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1008\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1009\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1010\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1011\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplitter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1012\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1013\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) < \u001B[32m1\u001B[39m:\n\u001B[32m   1016\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1017\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mNo fits were performed. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1018\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWas the CV iterator empty? \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1019\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWere there no candidates?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1020\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     73\u001B[39m warning_filters = warnings.filters\n\u001B[32m     74\u001B[39m iterable_with_config_and_warning_filters = (\n\u001B[32m     75\u001B[39m     (\n\u001B[32m     76\u001B[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001B[32m   (...)\u001B[39m\u001B[32m     80\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     81\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m82\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config_and_warning_filters\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/joblib/parallel.py:1986\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1984\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1985\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1986\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[32m   1988\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1989\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1990\u001B[39m \u001B[38;5;66;03m# reused, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1991\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1992\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1993\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/joblib/parallel.py:1914\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1912\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1913\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1914\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1915\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1916\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:147\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config), warnings.catch_warnings():\n\u001B[32m    146\u001B[39m     warnings.filters = warning_filters\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:859\u001B[39m, in \u001B[36m_fit_and_score\u001B[39m\u001B[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[39m\n\u001B[32m    857\u001B[39m         estimator.fit(X_train, **fit_params)\n\u001B[32m    858\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m859\u001B[39m         \u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    861\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    862\u001B[39m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[32m    863\u001B[39m     fit_time = time.time() - start_time\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/scikeras/wrappers.py:770\u001B[39m, in \u001B[36mBaseWrapper.fit\u001B[39m\u001B[34m(self, X, y, sample_weight, **kwargs)\u001B[39m\n\u001B[32m    765\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33mepochs\u001B[39m\u001B[33m\"\u001B[39m] = kwargs.get(\n\u001B[32m    766\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mepochs\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mfit__epochs\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m.epochs)\n\u001B[32m    767\u001B[39m )\n\u001B[32m    768\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33minitial_epoch\u001B[39m\u001B[33m\"\u001B[39m] = kwargs.get(\u001B[33m\"\u001B[39m\u001B[33minitial_epoch\u001B[39m\u001B[33m\"\u001B[39m, \u001B[32m0\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m770\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    771\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    772\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    773\u001B[39m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    774\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwarm_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mwarm_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    775\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    776\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    778\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/scikeras/wrappers.py:938\u001B[39m, in \u001B[36mBaseWrapper._fit\u001B[39m\u001B[34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001B[39m\n\u001B[32m    934\u001B[39m X = \u001B[38;5;28mself\u001B[39m.feature_encoder_.transform(X)\n\u001B[32m    936\u001B[39m \u001B[38;5;28mself\u001B[39m._check_model_compatibility(y)\n\u001B[32m--> \u001B[39m\u001B[32m938\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit_keras_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    939\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    940\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    941\u001B[39m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    942\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwarm_start\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwarm_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m=\u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/scikeras/wrappers.py:535\u001B[39m, in \u001B[36mBaseWrapper._fit_keras_model\u001B[39m\u001B[34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001B[39m\n\u001B[32m    533\u001B[39m         hist = \u001B[38;5;28mself\u001B[39m.model_.fit(x=X, y=y, **fit_args)\n\u001B[32m    534\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m535\u001B[39m     hist = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel_\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    537\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m warm_start \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mhistory_\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m initial_epoch == \u001B[32m0\u001B[39m:\n\u001B[32m    538\u001B[39m     \u001B[38;5;28mself\u001B[39m.history_ = defaultdict(\u001B[38;5;28mlist\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001B[39m, in \u001B[36mTensorFlowTrainer.fit\u001B[39m\u001B[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[39m\n\u001B[32m    375\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m begin_step, end_step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[32m    376\u001B[39m     callbacks.on_train_batch_begin(begin_step)\n\u001B[32m--> \u001B[39m\u001B[32m377\u001B[39m     logs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    378\u001B[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001B[32m    379\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stop_training:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001B[39m, in \u001B[36mTensorFlowTrainer._make_function.<locals>.function\u001B[39m\u001B[34m(iterator)\u001B[39m\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfunction\u001B[39m(iterator):\n\u001B[32m    217\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[32m    218\u001B[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001B[32m    219\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m220\u001B[39m         opt_outputs = \u001B[43mmulti_step_on_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    221\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs.has_value():\n\u001B[32m    222\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    886\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    887\u001B[39m   \u001B[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001B[39;00m\n\u001B[32m    888\u001B[39m   initializers = []\n\u001B[32m--> \u001B[39m\u001B[32m889\u001B[39m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_initializers_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43minitializers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    890\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    891\u001B[39m   \u001B[38;5;66;03m# At this point we know that the initialization is complete (or less\u001B[39;00m\n\u001B[32m    892\u001B[39m   \u001B[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001B[39;00m\n\u001B[32m    893\u001B[39m   \u001B[38;5;28mself\u001B[39m._lock.release()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001B[39m, in \u001B[36mFunction._initialize\u001B[39m\u001B[34m(self, args, kwds, add_initializers_to)\u001B[39m\n\u001B[32m    691\u001B[39m \u001B[38;5;28mself\u001B[39m._variable_creation_config = \u001B[38;5;28mself\u001B[39m._generate_scoped_tracing_options(\n\u001B[32m    692\u001B[39m     variable_capturing_scope,\n\u001B[32m    693\u001B[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001B[32m    694\u001B[39m )\n\u001B[32m    695\u001B[39m \u001B[38;5;66;03m# Force the definition of the function for these arguments\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m696\u001B[39m \u001B[38;5;28mself\u001B[39m._concrete_variable_creation_fn = \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrace_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    697\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[32m    698\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    700\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvalid_creator_scope\u001B[39m(*unused_args, **unused_kwds):\n\u001B[32m    701\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Disables variable creation.\"\"\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001B[39m, in \u001B[36mtrace_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    175\u001B[39m     args = tracing_options.input_signature\n\u001B[32m    176\u001B[39m     kwargs = {}\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m   concrete_function = \u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracing_options.bind_graph_to_function:\n\u001B[32m    183\u001B[39m   concrete_function._garbage_collector.release()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001B[39m, in \u001B[36m_maybe_define_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    281\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    282\u001B[39m   target_func_type = lookup_func_type\n\u001B[32m--> \u001B[39m\u001B[32m283\u001B[39m concrete_function = \u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_func_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookup_func_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m tracing_options.function_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    288\u001B[39m   tracing_options.function_cache.add(\n\u001B[32m    289\u001B[39m       concrete_function, current_func_context\n\u001B[32m    290\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001B[39m, in \u001B[36m_create_concrete_function\u001B[39m\u001B[34m(function_type, type_context, func_graph, tracing_options)\u001B[39m\n\u001B[32m    303\u001B[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001B[32m    304\u001B[39m       placeholder_context\n\u001B[32m    305\u001B[39m   )\n\u001B[32m    307\u001B[39m disable_acd = tracing_options.attributes \u001B[38;5;129;01mand\u001B[39;00m tracing_options.attributes.get(\n\u001B[32m    308\u001B[39m     attributes_lib.DISABLE_ACD, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    309\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m310\u001B[39m traced_func_graph = \u001B[43mfunc_graph_module\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpython_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m    \u001B[49m\u001B[43madd_control_dependencies\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdisable_acd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m    \u001B[49m\u001B[43marg_names\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction_type_utils\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_arg_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    322\u001B[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001B[32m    324\u001B[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1060\u001B[39m, in \u001B[36mfunc_graph_from_py_func\u001B[39m\u001B[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001B[39m\n\u001B[32m   1057\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[32m   1059\u001B[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001B[32m-> \u001B[39m\u001B[32m1060\u001B[39m func_outputs = \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1062\u001B[39m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[32m   1063\u001B[39m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[32m   1064\u001B[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001B[39m, in \u001B[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001B[39m\u001B[34m(*args, **kwds)\u001B[39m\n\u001B[32m    595\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m default_graph._variable_creator_scope(scope, priority=\u001B[32m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[32m    596\u001B[39m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[32m    597\u001B[39m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[32m    598\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[32m--> \u001B[39m\u001B[32m599\u001B[39m     out = \u001B[43mweak_wrapped_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__wrapped__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    600\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001B[39m, in \u001B[36mpy_func_from_autograph.<locals>.autograph_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     39\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001B[39;00m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapi\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m      \u001B[49m\u001B[43moriginal_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[43m      \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[43m      \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconverter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mConversionOptions\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[43m          \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m          \u001B[49m\u001B[43moptional_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m          \u001B[49m\u001B[43muser_requested\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[32m     51\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[33m\"\u001B[39m\u001B[33mag_error_metadata\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:339\u001B[39m, in \u001B[36mconverted_call\u001B[39m\u001B[34m(f, args, kwargs, caller_fn_scope, options)\u001B[39m\n\u001B[32m    337\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_autograph_artifact(f):\n\u001B[32m    338\u001B[39m   logging.log(\u001B[32m2\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mPermanently allowed: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: AutoGraph artifact\u001B[39m\u001B[33m'\u001B[39m, f)\n\u001B[32m--> \u001B[39m\u001B[32m339\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001B[39;00m\n\u001B[32m    342\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f, functools.partial):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[39m, in \u001B[36m_call_unconverted\u001B[39m\u001B[34m(f, args, kwargs, options, update_cache)\u001B[39m\n\u001B[32m    456\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m f.\u001B[34m__self__\u001B[39m.call(args, kwargs)\n\u001B[32m    458\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m459\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    460\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m f(*args)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001B[39m, in \u001B[36mdo_not_convert.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    641\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m    642\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001B[32m--> \u001B[39m\u001B[32m643\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:133\u001B[39m, in \u001B[36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001B[39m\u001B[34m(iterator)\u001B[39m\n\u001B[32m    129\u001B[39m \u001B[38;5;129m@tf\u001B[39m.autograph.experimental.do_not_convert\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmulti_step_on_iterator\u001B[39m(iterator):\n\u001B[32m    131\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.steps_per_execution == \u001B[32m1\u001B[39m:\n\u001B[32m    132\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m tf.experimental.Optional.from_value(\n\u001B[32m--> \u001B[39m\u001B[32m133\u001B[39m             \u001B[43mone_step_on_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_next\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    134\u001B[39m         )\n\u001B[32m    136\u001B[39m     \u001B[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001B[39;00m\n\u001B[32m    137\u001B[39m     empty_outputs = tf.experimental.Optional.empty(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:906\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    902\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall through to cond-based initialization.\u001B[39;00m\n\u001B[32m    903\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    904\u001B[39m     \u001B[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001B[39;00m\n\u001B[32m    905\u001B[39m     \u001B[38;5;66;03m# no_variable_creation function.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m906\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    907\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[32m    908\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    909\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    910\u001B[39m   bound_args = \u001B[38;5;28mself\u001B[39m._concrete_variable_creation_fn.function_type.bind(\n\u001B[32m    911\u001B[39m       *args, **kwds\n\u001B[32m    912\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001B[39m, in \u001B[36mcall_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    130\u001B[39m args = args \u001B[38;5;28;01mif\u001B[39;00m args \u001B[38;5;28;01melse\u001B[39;00m ()\n\u001B[32m    131\u001B[39m kwargs = kwargs \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[32m--> \u001B[39m\u001B[32m132\u001B[39m function = \u001B[43mtrace_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    133\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[32m    134\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001B[39;00m\n\u001B[32m    137\u001B[39m bound_args = function.function_type.bind(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001B[39m, in \u001B[36mtrace_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    175\u001B[39m     args = tracing_options.input_signature\n\u001B[32m    176\u001B[39m     kwargs = {}\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m   concrete_function = \u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracing_options.bind_graph_to_function:\n\u001B[32m    183\u001B[39m   concrete_function._garbage_collector.release()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001B[39m, in \u001B[36m_maybe_define_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    281\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    282\u001B[39m   target_func_type = lookup_func_type\n\u001B[32m--> \u001B[39m\u001B[32m283\u001B[39m concrete_function = \u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_func_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookup_func_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m tracing_options.function_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    288\u001B[39m   tracing_options.function_cache.add(\n\u001B[32m    289\u001B[39m       concrete_function, current_func_context\n\u001B[32m    290\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001B[39m, in \u001B[36m_create_concrete_function\u001B[39m\u001B[34m(function_type, type_context, func_graph, tracing_options)\u001B[39m\n\u001B[32m    303\u001B[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001B[32m    304\u001B[39m       placeholder_context\n\u001B[32m    305\u001B[39m   )\n\u001B[32m    307\u001B[39m disable_acd = tracing_options.attributes \u001B[38;5;129;01mand\u001B[39;00m tracing_options.attributes.get(\n\u001B[32m    308\u001B[39m     attributes_lib.DISABLE_ACD, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    309\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m310\u001B[39m traced_func_graph = \u001B[43mfunc_graph_module\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpython_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m    \u001B[49m\u001B[43madd_control_dependencies\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdisable_acd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m    \u001B[49m\u001B[43marg_names\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction_type_utils\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_arg_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    322\u001B[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001B[32m    324\u001B[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1060\u001B[39m, in \u001B[36mfunc_graph_from_py_func\u001B[39m\u001B[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001B[39m\n\u001B[32m   1057\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[32m   1059\u001B[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001B[32m-> \u001B[39m\u001B[32m1060\u001B[39m func_outputs = \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1062\u001B[39m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[32m   1063\u001B[39m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[32m   1064\u001B[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001B[39m, in \u001B[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001B[39m\u001B[34m(*args, **kwds)\u001B[39m\n\u001B[32m    595\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m default_graph._variable_creator_scope(scope, priority=\u001B[32m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[32m    596\u001B[39m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[32m    597\u001B[39m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[32m    598\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[32m--> \u001B[39m\u001B[32m599\u001B[39m     out = \u001B[43mweak_wrapped_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__wrapped__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    600\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001B[39m, in \u001B[36mpy_func_from_autograph.<locals>.autograph_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     39\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001B[39;00m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapi\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m      \u001B[49m\u001B[43moriginal_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[43m      \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[43m      \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconverter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mConversionOptions\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[43m          \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m          \u001B[49m\u001B[43moptional_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m          \u001B[49m\u001B[43muser_requested\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[32m     51\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[33m\"\u001B[39m\u001B[33mag_error_metadata\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001B[39m, in \u001B[36mconverted_call\u001B[39m\u001B[34m(f, args, kwargs, caller_fn_scope, options)\u001B[39m\n\u001B[32m    329\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m conversion.is_in_allowlist_cache(f, options):\n\u001B[32m    330\u001B[39m   logging.log(\u001B[32m2\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mAllowlisted \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: from cache\u001B[39m\u001B[33m'\u001B[39m, f)\n\u001B[32m--> \u001B[39m\u001B[32m331\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    333\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ag_ctx.control_status_ctx().status == ag_ctx.Status.DISABLED:\n\u001B[32m    334\u001B[39m   logging.log(\u001B[32m2\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mAllowlisted: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: AutoGraph is disabled in context\u001B[39m\u001B[33m'\u001B[39m, f)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[39m, in \u001B[36m_call_unconverted\u001B[39m\u001B[34m(f, args, kwargs, options, update_cache)\u001B[39m\n\u001B[32m    456\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m f.\u001B[34m__self__\u001B[39m.call(args, kwargs)\n\u001B[32m    458\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m459\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    460\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m f(*args)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001B[39m, in \u001B[36mdo_not_convert.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    641\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m    642\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001B[32m--> \u001B[39m\u001B[32m643\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:114\u001B[39m, in \u001B[36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001B[39m\u001B[34m(data)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;129m@tf\u001B[39m.autograph.experimental.do_not_convert\n\u001B[32m    112\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mone_step_on_data\u001B[39m(data):\n\u001B[32m    113\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdistribute_strategy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    115\u001B[39m     outputs = reduce_per_replica(\n\u001B[32m    116\u001B[39m         outputs,\n\u001B[32m    117\u001B[39m         \u001B[38;5;28mself\u001B[39m.distribute_strategy,\n\u001B[32m    118\u001B[39m         reduction=\u001B[33m\"\u001B[39m\u001B[33mauto\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    119\u001B[39m     )\n\u001B[32m    120\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001B[39m, in \u001B[36mStrategyBase.run\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m   1668\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.scope():\n\u001B[32m   1669\u001B[39m   \u001B[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001B[39;00m\n\u001B[32m   1670\u001B[39m   \u001B[38;5;66;03m# applied when the caller is also in Eager mode.\u001B[39;00m\n\u001B[32m   1671\u001B[39m   fn = autograph.tf_convert(\n\u001B[32m   1672\u001B[39m       fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m1673\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_extended\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001B[39m, in \u001B[36mStrategyExtendedV1.call_for_each_replica\u001B[39m\u001B[34m(self, fn, args, kwargs)\u001B[39m\n\u001B[32m   3261\u001B[39m   kwargs = {}\n\u001B[32m   3262\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._container_strategy().scope():\n\u001B[32m-> \u001B[39m\u001B[32m3263\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001B[39m, in \u001B[36m_DefaultDistributionExtended._call_for_each_replica\u001B[39m\u001B[34m(self, fn, args, kwargs)\u001B[39m\n\u001B[32m   4059\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_call_for_each_replica\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[32m   4060\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m ReplicaContext(\u001B[38;5;28mself\u001B[39m._container_strategy(), replica_id_in_sync_group=\u001B[32m0\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m4061\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001B[39m, in \u001B[36mdo_not_convert.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    641\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m    642\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001B[32m--> \u001B[39m\u001B[32m643\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:81\u001B[39m, in \u001B[36mTensorFlowTrainer.train_step\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m     78\u001B[39m     gradients = tape.gradient(loss, trainable_weights)\n\u001B[32m     80\u001B[39m     \u001B[38;5;66;03m# Update weights\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgradients\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainable_weights\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     82\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     83\u001B[39m     warnings.warn(\u001B[33m\"\u001B[39m\u001B[33mThe model does not have any trainable weights.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:463\u001B[39m, in \u001B[36mBaseOptimizer.apply_gradients\u001B[39m\u001B[34m(self, grads_and_vars)\u001B[39m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply_gradients\u001B[39m(\u001B[38;5;28mself\u001B[39m, grads_and_vars):\n\u001B[32m    462\u001B[39m     grads, trainable_variables = \u001B[38;5;28mzip\u001B[39m(*grads_and_vars)\n\u001B[32m--> \u001B[39m\u001B[32m463\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    464\u001B[39m     \u001B[38;5;66;03m# Return iterations for compat with tf.keras.\u001B[39;00m\n\u001B[32m    465\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._iterations\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:527\u001B[39m, in \u001B[36mBaseOptimizer.apply\u001B[39m\u001B[34m(self, grads, trainable_variables)\u001B[39m\n\u001B[32m    524\u001B[39m     grads = [g \u001B[38;5;28;01mif\u001B[39;00m g \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m g / scale \u001B[38;5;28;01mfor\u001B[39;00m g \u001B[38;5;129;01min\u001B[39;00m grads]\n\u001B[32m    526\u001B[39m \u001B[38;5;66;03m# Apply gradient updates.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m527\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_backend_apply_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    528\u001B[39m \u001B[38;5;66;03m# Apply variable constraints after applying gradients.\u001B[39;00m\n\u001B[32m    529\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m variable \u001B[38;5;129;01min\u001B[39;00m trainable_variables:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:593\u001B[39m, in \u001B[36mBaseOptimizer._backend_apply_gradients\u001B[39m\u001B[34m(self, grads, trainable_variables)\u001B[39m\n\u001B[32m    590\u001B[39m     \u001B[38;5;28mself\u001B[39m._apply_weight_decay(trainable_variables)\n\u001B[32m    592\u001B[39m     \u001B[38;5;66;03m# Run update step.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m593\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_backend_update_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    594\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlearning_rate\u001B[49m\n\u001B[32m    595\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    597\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.use_ema:\n\u001B[32m    598\u001B[39m     \u001B[38;5;28mself\u001B[39m._update_model_variables_moving_average(\n\u001B[32m    599\u001B[39m         \u001B[38;5;28mself\u001B[39m._trainable_variables\n\u001B[32m    600\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:120\u001B[39m, in \u001B[36mTFOptimizer._backend_update_step\u001B[39m\u001B[34m(self, grads, trainable_variables, learning_rate)\u001B[39m\n\u001B[32m    118\u001B[39m grads_and_vars = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(grads, trainable_variables))\n\u001B[32m    119\u001B[39m grads_and_vars = \u001B[38;5;28mself\u001B[39m._all_reduce_sum_gradients(grads_and_vars)\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m \u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__internal__\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdistribute\u001B[49m\u001B[43m.\u001B[49m\u001B[43minterim\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmaybe_merge_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    121\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_distributed_tf_update_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_distribution_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrads_and_vars\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001B[39m, in \u001B[36mmaybe_merge_call\u001B[39m\u001B[34m(fn, strategy, *args, **kwargs)\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001B[39;00m\n\u001B[32m     32\u001B[39m \n\u001B[32m     33\u001B[39m \u001B[33;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     48\u001B[39m \u001B[33;03m  The return value of the `fn` call.\u001B[39;00m\n\u001B[32m     49\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m strategy_supports_no_merge_call():\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     52\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     53\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m distribute_lib.get_replica_context().merge_call(\n\u001B[32m     54\u001B[39m       fn, args=args, kwargs=kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:134\u001B[39m, in \u001B[36mTFOptimizer._distributed_tf_update_step\u001B[39m\u001B[34m(self, distribution, grads_and_vars, learning_rate)\u001B[39m\n\u001B[32m    131\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.update_step(grad, var, learning_rate)\n\u001B[32m    133\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m grad, var \u001B[38;5;129;01min\u001B[39;00m grads_and_vars:\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m     \u001B[43mdistribution\u001B[49m\u001B[43m.\u001B[49m\u001B[43mextended\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    135\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[43m        \u001B[49m\u001B[43mapply_grad_to_update_var\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    137\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3007\u001B[39m, in \u001B[36mStrategyExtendedV2.update\u001B[39m\u001B[34m(self, var, fn, args, kwargs, group)\u001B[39m\n\u001B[32m   3005\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._update(var, fn, args, kwargs, group)\n\u001B[32m   3006\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3007\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_replica_ctx_update\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3008\u001B[39m \u001B[43m      \u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:2886\u001B[39m, in \u001B[36mStrategyExtendedV2._replica_ctx_update\u001B[39m\u001B[34m(self, var, fn, args, kwargs, group)\u001B[39m\n\u001B[32m   2883\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmerge_fn\u001B[39m(_, *merged_args, **merged_kwargs):\n\u001B[32m   2884\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.update(var, fn, merged_args, merged_kwargs, group=group)\n\u001B[32m-> \u001B[39m\u001B[32m2886\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreplica_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmerge_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmerge_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3478\u001B[39m, in \u001B[36mReplicaContextBase.merge_call\u001B[39m\u001B[34m(self, merge_fn, args, kwargs)\u001B[39m\n\u001B[32m   3474\u001B[39m   kwargs = {}\n\u001B[32m   3476\u001B[39m merge_fn = autograph.tf_convert(\n\u001B[32m   3477\u001B[39m     merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m3478\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_merge_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmerge_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3485\u001B[39m, in \u001B[36mReplicaContextBase._merge_call\u001B[39m\u001B[34m(self, merge_fn, args, kwargs)\u001B[39m\n\u001B[32m   3482\u001B[39m _push_per_thread_mode(  \u001B[38;5;66;03m# thread-local, so not needed with multiple threads\u001B[39;00m\n\u001B[32m   3483\u001B[39m     _CrossReplicaThreadMode(\u001B[38;5;28mself\u001B[39m._strategy))  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[32m   3484\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3485\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmerge_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_strategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3486\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   3487\u001B[39m   _pop_per_thread_mode()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001B[39m, in \u001B[36mdo_not_convert.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    641\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m    642\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001B[32m--> \u001B[39m\u001B[32m643\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:2884\u001B[39m, in \u001B[36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001B[39m\u001B[34m(_, *merged_args, **merged_kwargs)\u001B[39m\n\u001B[32m   2883\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmerge_fn\u001B[39m(_, *merged_args, **merged_kwargs):\n\u001B[32m-> \u001B[39m\u001B[32m2884\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmerged_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmerged_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001B[39m, in \u001B[36mStrategyExtendedV2.update\u001B[39m\u001B[34m(self, var, fn, args, kwargs, group)\u001B[39m\n\u001B[32m   3002\u001B[39m   fn = autograph.tf_convert(\n\u001B[32m   3003\u001B[39m       fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   3004\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._container_strategy().scope():\n\u001B[32m-> \u001B[39m\u001B[32m3005\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3006\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   3007\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._replica_ctx_update(\n\u001B[32m   3008\u001B[39m       var, fn, args=args, kwargs=kwargs, group=group)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001B[39m, in \u001B[36m_DefaultDistributionExtended._update\u001B[39m\u001B[34m(self, var, fn, args, kwargs, group)\u001B[39m\n\u001B[32m   4072\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_update\u001B[39m(\u001B[38;5;28mself\u001B[39m, var, fn, args, kwargs, group):\n\u001B[32m   4073\u001B[39m   \u001B[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001B[39;00m\n\u001B[32m   4074\u001B[39m   \u001B[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4075\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_update_non_slot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001B[39m, in \u001B[36m_DefaultDistributionExtended._update_non_slot\u001B[39m\u001B[34m(self, colocate_with, fn, args, kwargs, should_group)\u001B[39m\n\u001B[32m   4077\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_update_non_slot\u001B[39m(\u001B[38;5;28mself\u001B[39m, colocate_with, fn, args, kwargs, should_group):\n\u001B[32m   4078\u001B[39m   \u001B[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001B[39;00m\n\u001B[32m   4079\u001B[39m   \u001B[38;5;66;03m# once that value is used for something.\u001B[39;00m\n\u001B[32m   4080\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m UpdateContext(colocate_with):\n\u001B[32m-> \u001B[39m\u001B[32m4081\u001B[39m     result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4082\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m should_group:\n\u001B[32m   4083\u001B[39m       \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001B[39m, in \u001B[36mdo_not_convert.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    641\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m    642\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001B[32m--> \u001B[39m\u001B[32m643\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:131\u001B[39m, in \u001B[36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001B[39m\u001B[34m(var, grad, learning_rate)\u001B[39m\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply_grad_to_update_var\u001B[39m(var, grad, learning_rate):\n\u001B[32m--> \u001B[39m\u001B[32m131\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mupdate_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/optimizers/adam.py:104\u001B[39m, in \u001B[36mAdam.update_step\u001B[39m\u001B[34m(self, gradient, variable, learning_rate)\u001B[39m\n\u001B[32m    102\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mupdate_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, gradient, variable, learning_rate):\n\u001B[32m    103\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Update step given gradient and the associated model variable.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m104\u001B[39m     lr = \u001B[43mops\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    105\u001B[39m     gradient = ops.cast(gradient, variable.dtype)\n\u001B[32m    106\u001B[39m     local_step = ops.cast(\u001B[38;5;28mself\u001B[39m.iterations + \u001B[32m1\u001B[39m, variable.dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/ops/core.py:835\u001B[39m, in \u001B[36mcast\u001B[39m\u001B[34m(x, dtype)\u001B[39m\n\u001B[32m    833\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors((x,)):\n\u001B[32m    834\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Cast(dtype=dtype)(x)\n\u001B[32m--> \u001B[39m\u001B[32m835\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbackend\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcore\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/core.py:217\u001B[39m, in \u001B[36mcast\u001B[39m\u001B[34m(x, dtype)\u001B[39m\n\u001B[32m    215\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1264\u001B[39m, in \u001B[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m   1262\u001B[39m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[32m   1263\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1264\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1265\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[32m   1266\u001B[39m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[32m   1267\u001B[39m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[32m   1268\u001B[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py:1000\u001B[39m, in \u001B[36mcast\u001B[39m\u001B[34m(x, dtype, name)\u001B[39m\n\u001B[32m    996\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    997\u001B[39m     \u001B[38;5;28misinstance\u001B[39m(x, tensor_lib.Tensor) \u001B[38;5;129;01mor\u001B[39;00m _pywrap_utils.IsResourceVariable(x)\n\u001B[32m    998\u001B[39m ) \u001B[38;5;129;01mand\u001B[39;00m base_type == x.dtype:\n\u001B[32m    999\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[32m-> \u001B[39m\u001B[32m1000\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mops\u001B[49m\u001B[43m.\u001B[49m\u001B[43mname_scope\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mCast\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1001\u001B[39m \u001B[43m  \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse_tensor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSparseTensor\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1002\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalues_cast\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbase_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5644\u001B[39m, in \u001B[36minternal_name_scope_v1.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   5642\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   5643\u001B[39m   \u001B[38;5;28mself\u001B[39m._name_scope = g.name_scope(\u001B[38;5;28mself\u001B[39m._name)\n\u001B[32m-> \u001B[39m\u001B[32m5644\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_name_scope\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__enter__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   5645\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[32m   5646\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._g_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:137\u001B[39m, in \u001B[36m_GeneratorContextManager.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args, \u001B[38;5;28mself\u001B[39m.kwds, \u001B[38;5;28mself\u001B[39m.func\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.gen)\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m    139\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mgenerator didn\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt yield\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:3406\u001B[39m, in \u001B[36mGraph.name_scope\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   3403\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(name, compat.bytes_or_text_types):\n\u001B[32m   3404\u001B[39m   name = compat.as_str(name)\n\u001B[32m-> \u001B[39m\u001B[32m3406\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_name_stack\u001B[49m:\n\u001B[32m   3407\u001B[39m   \u001B[38;5;66;03m# Scopes created in a nested scope may have initial characters\u001B[39;00m\n\u001B[32m   3408\u001B[39m   \u001B[38;5;66;03m# that are illegal as the initial character of an op name\u001B[39;00m\n\u001B[32m   3409\u001B[39m   \u001B[38;5;66;03m# (viz. '-', '\\', '/', and '_').\u001B[39;00m\n\u001B[32m   3410\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _VALID_SCOPE_NAME_REGEX.match(name):\n\u001B[32m   3411\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   3412\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m is not a valid scope name. A scope name has to match \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   3413\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mthe following pattern: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_VALID_SCOPE_NAME_REGEX.pattern\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Personal Project/Quant/Market-Context-Project/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:3305\u001B[39m, in \u001B[36mGraph._name_stack\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   3302\u001B[39m   \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   3303\u001B[39m     \u001B[38;5;28mself\u001B[39m._default_original_op = old_original_op\n\u001B[32m-> \u001B[39m\u001B[32m3305\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m   3306\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_name_stack\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> \u001B[38;5;28mstr\u001B[39m:\n\u001B[32m   3307\u001B[39m   \u001B[38;5;66;03m# This may be called from a thread where name_stack doesn't yet exist.\u001B[39;00m\n\u001B[32m   3308\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m._thread_local, \u001B[33m\"\u001B[39m\u001B[33m_name_stack\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m   3309\u001B[39m     \u001B[38;5;28mself\u001B[39m._thread_local._name_stack = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_rmse = np.sqrt(-random_search.best_score_)\n",
    "\n",
    "# Structure the best_result for consistency with subsequent cells\n",
    "best_result = {\n",
    "    'embed_dim': best_params['model__embed_dim'],\n",
    "    'num_heads': best_params['model__num_heads'],\n",
    "    'ff_dim': best_params['model__ff_dim'],\n",
    "    'num_transformer_blocks': best_params['model__num_transformer_blocks'],\n",
    "    'dropout_rate': best_params['model__dropout_rate'],\n",
    "    'learning_rate': best_params['model__learning_rate'],\n",
    "    'batch_size': best_params['batch_size'],\n",
    "    'epochs': best_params['epochs'],\n",
    "    'rmse': best_rmse,\n",
    "    'val_loss': -random_search.best_score_ # Use the best negative MSE as val_loss placeholder\n",
    "}\n",
    "\n",
    "print(\"\\nTop Parameter Combination:\")\n",
    "print(best_result)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Best Parameters Found (from RandomizedSearchCV):\")\n",
    "print(\"=\"*60)\n",
    "for param, value in best_result.items():\n",
    "    if param not in ['val_loss', 'rmse']:\n",
    "        print(f\"{param:25s}: {value}\")\n",
    "print(f\"{'Validation RMSE':25s}: {best_result['rmse']:.4f}\")\n",
    "print(f\"{'Best Val Loss (neg_mse)':25s}: {best_result['val_loss']:.6f}\") # Note: This is negative MSE from scoring\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "final_model = build_transformer_model(\n",
    "    look_back, num_features,\n",
    "    embed_dim=best_result['embed_dim'],\n",
    "    num_heads=best_result['num_heads'],\n",
    "    ff_dim=best_result['ff_dim'],\n",
    "    num_transformer_blocks=best_result['num_transformer_blocks'],\n",
    "    dropout_rate=best_result['dropout_rate'],\n",
    "    learning_rate=best_result['learning_rate']\n",
    ")\n",
    "\n",
    "# Callbacks are now defined above and used by RandomizedSearchCV directly.\n",
    "# These definitions are for the final model training if needed with specific patience.\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "model_check_point = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "final_model.summary()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n--- Training Final Model ---\")\n",
    "history = final_model.fit(\n",
    "    X_train_scaled,\n",
    "    Y_train_scaled,\n",
    "    epochs=best_result['epochs'],\n",
    "    batch_size=best_result['batch_size'],\n",
    "    validation_data=(X_val_scaled, Y_val_scaled),\n",
    "    callbacks=[early_stop, reduce_lr, model_check_point],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"Completed training the final model.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_training_history(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Loss plot\n",
    "    axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0].set_title('Model Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # MAE plot\n",
    "    axes[1].plot(history.history['mae'], label='Training MAE')\n",
    "    axes[1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "    axes[1].set_title('Model MAE')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_training_history(history)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_predict_scaled = final_model.predict(X_test_scaled)\n",
    "\n",
    "predicted_prices = scaler_y.inverse_transform(test_predict_scaled).flatten()\n",
    "actual_prices = scaler_y.inverse_transform(Y_test_scaled.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(actual_prices, predicted_prices))\n",
    "test_mae = mean_absolute_error(actual_prices, predicted_prices)\n",
    "test_r2 = r2_score(actual_prices, predicted_prices)\n",
    "mape = mean_absolute_percentage_error(actual_prices, predicted_prices)\n",
    "\n",
    "print(f\"\\n--- Price Prediction Performance Evaluation ---\")\n",
    "print(f\"Test Data RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_dates = df.index[len(df) - len(Y_test) - 1 : len(df) - 1]\n",
    "\n",
    "window = (-49,-1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_dates[window[0]:window[1]], actual_prices[window[0]:window[1]], label='Actual Price')\n",
    "plt.plot(test_dates[window[0]:window[1]], predicted_prices[window[0]:window[1]], label='Predicted Price')\n",
    "plt.title(f'Price Prediction vs. Actual (RMSE: {test_rmse:.2f})')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def comprehensive_evaluation(actual, predicted, model):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    mape = mean_absolute_error(actual, predicted)\n",
    "\n",
    "    test_dates = df.index[len(df) - len(Y_test) - 1 : len(df) - 1]\n",
    "    actual_dir = np.sign(np.diff(actual))\n",
    "    pred_dir = np.sign(np.diff(predicted))\n",
    "    dir_acc = accuracy_score((actual_dir > 0).astype(int),\n",
    "                             (pred_dir > 0).astype(int))\n",
    "\n",
    "    residuals = actual - predicted\n",
    "\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"           Transformer Price Performance Metrics         \")\n",
    "    print(\"=======================================================\")\n",
    "    print(f\"1. RMSE (Root Mean Squared Error):        {rmse:.4f}\")\n",
    "    print(f\"2. MAE (Mean Absolute Error):             {mae:.4f}\")\n",
    "    print(f\"3. MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "    print(f\"4. R:                                    {r2:.4f}\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    axes[0, 0].scatter(actual, predicted, alpha=0.5)\n",
    "    axes[0, 0].plot([actual.min(), actual.max()],\n",
    "                    [actual.min(), actual.max()],\n",
    "                    'r--', lw=2)\n",
    "    axes[0, 0].set_xlabel('Actual Price')\n",
    "    axes[0, 0].set_ylabel('Predicted Price')\n",
    "    axes[0, 0].set_title('Actual vs Predicted')\n",
    "    axes[0, 0].grid(True)\n",
    "\n",
    "    axes[0, 1].hist(residuals, bins=50, edgecolor='black')\n",
    "    axes[0, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Residual')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title(f'Residual Distribution (Mean: {residuals.mean():.2f})')\n",
    "    axes[0, 1].grid(True)\n",
    "\n",
    "    axes[1, 0].plot(test_dates, residuals)\n",
    "    axes[1, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Date')\n",
    "    axes[1, 0].set_ylabel('Residual')\n",
    "    axes[1, 0].set_title('Residuals Over Time')\n",
    "    axes[1, 0].xaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(True)\n",
    "\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[1, 1])\n",
    "    axes[1, 1].set_title('Q-Q Plot')\n",
    "    axes[1, 1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'mape': mape,\n",
    "        'r2': r2,\n",
    "        'directional_accuracy': dir_acc,\n",
    "        'residual_mean': residuals.mean(),\n",
    "        'residual_std': residuals.std()\n",
    "    }"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "_ = comprehensive_evaluation(actual_prices, predicted_prices, final_model)"
  },
  {
   "metadata": {
    "id": "Y-Zo7Hjvn29-"
   },
   "cell_type": "markdown",
   "source": "# Model Manager"
  },
  {
   "metadata": {
    "id": "vc92THVfn4mX",
    "ExecuteTime": {
     "end_time": "2025-11-26T03:24:01.057113Z",
     "start_time": "2025-10-12T22:28:31.083454Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 8,
   "source": [
    "class ModelManager:\n",
    "    def __init__(self, model, base_dir=\"../trained_model\"):\n",
    "        self.model = model\n",
    "        self.base_dir = base_dir\n",
    "        tf.io.gfile.makedirs(self.base_dir)\n",
    "\n",
    "    def save_weights(self, tag):\n",
    "        file_path = os.path.join(self.base_dir, f\"weights_{tag}.h5\")\n",
    "        self.model.save_weights(file_path)\n",
    "        print(f\"Weights saved: {file_path}\")\n",
    "        return file_path\n",
    "\n",
    "    def load_weights(self, tag):\n",
    "        file_path = os.path.join(self.base_dir, f\"weights_{tag}.h5\")\n",
    "        try:\n",
    "            self.model.load_weights(file_path)\n",
    "            print(f\"Weights loaded: {file_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading weights: {e}\")\n",
    "            return False\n",
    "\n",
    "    def save_model(self, tag, save_format='tf'):\n",
    "        model_path = os.path.join(self.base_dir, f\"model_{tag}\")\n",
    "        # save_format: 'tf' -> saved model directory, 'h5' -> single file if desired\n",
    "        if save_format == 'h5':\n",
    "            self.model.save(f\"{model_path}.h5\", include_optimizer=True)\n",
    "        else:\n",
    "            self.model.save(model_path)  # SavedModel dir\n",
    "        print(f\"Model saved: {model_path}\")\n",
    "        return model_path\n",
    "\n",
    "    @staticmethod\n",
    "    def load_full_model(tag, base_dir=\"../trained_model\"):\n",
    "        model_path = os.path.join(base_dir, f\"model_{tag}\")\n",
    "        try:\n",
    "            loaded_model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"Model loaded: {model_path}\")\n",
    "            return loaded_model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            return None"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mm = ModelManager(final_model, base_dir=\"../trained_model\")\n",
    "mm.save_model(\"transformer_v1\", save_format='tf')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Further Steps"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Calculate irrationality index based on prediction errors and the actual market movement.\n",
    "- Error = Actual - Predicted\n",
    "- I = (Error - Mean(Error)) / StdDev(Error)"
   ]
  }
 ]
}
